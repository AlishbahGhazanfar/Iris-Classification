{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817fca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from BankNotes import BankNote\n",
    "from fastapi import FastAPI\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2cc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "scaler = StandardScaler()  # Assuming 'scaler' is the StandardScaler used for preprocessing\n",
    "\n",
    "# Create a FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Define a Pydantic model for the request body\n",
    "class IrisData(BaseModel):\n",
    "    sepal_length: float\n",
    "    sepal_width: float\n",
    "    petal_length: float\n",
    "    petal_width: float\n",
    "\n",
    "# Define a route for the prediction endpoint\n",
    "@app.post(\"/predict\")\n",
    "def predict_species(data: IrisData):\n",
    "    try:\n",
    "        # Prepare the data for prediction\n",
    "        new_data = np.array([[data.sepal_length, data.sepal_width, data.petal_length, data.petal_width]])\n",
    "        new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "        # Make the prediction\n",
    "        prediction = model.predict(new_data_scaled)\n",
    "\n",
    "        # Return the predicted class\n",
    "        return {\"predicted_species\": int(prediction[0])}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5690b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print message\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {\"message\":\"Hello,Welcome\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194b6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print message with string\n",
    "@app.get('/{name}')\n",
    "def get_name(name: str):\n",
    "    return {'message':f'Hello,{name}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ad05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app=FastAPI()\n",
    "\n",
    "#add two numbers\n",
    "\n",
    "class adddata(BaseModel):\n",
    "    a: int\n",
    "    b: int\n",
    "        \n",
    "@app.post(\"/add\")\n",
    "def add_numbers(data: adddata):\n",
    "    result=data.a+data.b\n",
    "    return{\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18db45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.post('/predict')\n",
    "# def predict_banknote(data:BankNote):\n",
    "#     data = data.dict()\n",
    "# #     print(data)\n",
    "# #     print('Hello')\n",
    "#     sepal_length = data['2.4']\n",
    "#     sepal_width = data['3.1']\n",
    "#     petal_length = data['5.7']\n",
    "#     petal_width = data['3.2']\n",
    "#     prediction = classifier.predict([[sepal_length, sepal_width, petal_length, petal_length]])\n",
    "# #     return {\n",
    "# #         'prediction': prediction\n",
    "# #     }\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87710138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.path.isfile('logistic_regression_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7679a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.getsize('logistic_regression_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de175f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [15624]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     ::1:63050 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     ::1:63051 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63051 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63052 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_15624\\3658997260.py\", line 21, in predict_species\n",
      "    new_data_scaled = scaler.transform(new_data)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 989, in transform\n",
      "    check_is_fitted(self)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1390, in check_is_fitted\n",
      "    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\n",
      "sklearn.exceptions.NotFittedError: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 407, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 69, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 758, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 778, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 299, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 79, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 74, in app\n",
      "    response = await func(request)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 278, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 193, in run_endpoint_function\n",
      "    return await run_in_threadpool(dependant.call, **values)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\starlette\\concurrency.py\", line 42, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_15624\\3658997260.py\", line 29, in predict_species\n",
      "    raise HTTPException(status_code=500, detail=str(e))\n",
      "NameError: name 'HTTPException' is not defined\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e62c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # Sample data\n",
    "# data = {\n",
    "#     \"sepal_length\": 5.1,\n",
    "#     \"sepal_width\": 3.5,\n",
    "#     \"petal_length\": 1.4,\n",
    "#     \"petal_width\": 0.2\n",
    "# }\n",
    "\n",
    "# # Send POST request to your FastAPI server\n",
    "# response = requests.post('http://localhost:8000/predict', json=data)\n",
    "\n",
    "# # Print the response\n",
    "# print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19795936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782edc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.post(\"/predict\")\n",
    "# def predict_species(data: IrisData):\n",
    "#     try:\n",
    "#         # Prepare the data for prediction\n",
    "#         new_data = np.array([[data.sepal_length, data.sepal_width, data.petal_length, data.petal_width]])\n",
    "#         new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "#         # Make the prediction\n",
    "#         prediction = model.predict(new_data_scaled)\n",
    "\n",
    "#         # Return the predicted class\n",
    "#         return {\"predicted_species\": int(prediction[0])}\n",
    "#     except Exception as e:\n",
    "#         return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eab03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [11068]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     ::1:62654 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     ::1:62655 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:62655 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     import nest_asyncio\n",
    "#     import uvicorn\n",
    "#     nest_asyncio.apply()\n",
    "#     uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8685182e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Preprocess the new data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m new_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m2.1\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m4.7\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m5.1\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m1.4\u001b[39m, \u001b[38;5;241m0.2\u001b[39m], [\u001b[38;5;241m6.2\u001b[39m, \u001b[38;5;241m2.9\u001b[39m, \u001b[38;5;241m4.3\u001b[39m, \u001b[38;5;241m1.3\u001b[39m]])\n\u001b[1;32m----> 9\u001b[0m new_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming 'scaler' is the StandardScaler used for preprocessing\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make predictions on the new data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_data_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:989\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    992\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    993\u001b[0m         X,\n\u001b[0;32m    994\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    999\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "\n",
    "# Preprocess the new data\n",
    "new_data = np.array([[2.1, 3.0, 4.7, 1.0], [5.1, 3.5, 1.4, 0.2], [6.2, 2.9, 4.3, 1.3]])\n",
    "new_data_scaled = scaler.transform(new_data)  # Assuming 'scaler' is the StandardScaler used for preprocessing\n",
    "\n",
    "# Make predictions on the new data\n",
    "predictions = model.predict(new_data_scaled)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bc9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
